{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeCoPSlnZ3K0T6GWvFzfT7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnff9/AD410_P2/blob/main/Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project 2: Optimizing Deep Learning Pipelines\n"
      ],
      "metadata": {
        "id": "zXpzWThsC563"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the Data from Kaggle:"
      ],
      "metadata": {
        "id": "6DZrwSYxDAxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1n1l6m1x07H",
        "outputId": "908326c4-d958-4b09-9e2c-87616e9d295b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "b0Uhg98mx31S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc8fff3-8de8-4cf8-fd62-e610144e666b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 219, in iter_dependencies\n",
            "    for req_string in self.metadata.get_all(\"Requires-Dist\", []):\n",
            "                      ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/functools.py\", line 998, in __get__\n",
            "    val = self.func(instance)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/base.py\", line 395, in metadata\n",
            "    self._add_egg_info_requires(metadata)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/base.py\", line 577, in _add_egg_info_requires\n",
            "    if not metadata.get_all(\"Provides-Extra\"):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/email/message.py\", line 545, in get_all\n",
            "    if k.lower() == name:\n",
            "       ^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 168, in emit\n",
            "    message = self.format(record)\n",
            "              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 999, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 119, in format\n",
            "    prefix += \" \" * get_indentation()\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 69, in get_indentation\n",
            "    def get_indentation() -> int:\n",
            "    \n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "pkX0kEOjx-Ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-_KF5ZQyD3o",
        "outputId": "e689b23d-874f-4e25-add3-4494bc54713f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                             title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "sadiajavedd/students-academic-performance-dataset               Students_Academic_Performance_Dataset                    8907  2025-10-23 04:16:35.563000           8577        219  1.0              \n",
            "zubairamuti/bmw-car-sales-record-2010-2024                      BMW Car Sales Record (2010-2024)                       853356  2025-11-19 04:50:35.480000            929         30  1.0              \n",
            "saadaliyaseen/shopping-behaviour-dataset                        Shopping Behaviour Dataset                              72165  2025-11-16 07:46:33.303000            689         27  1.0              \n",
            "ayeshaimran123/social-media-and-mental-health-balance           Social Media and Mental Health Balance                   5941  2025-10-26 07:51:53.380000           7787        107  1.0              \n",
            "shahzadi786/world-smartphone-market-2025                        World Smartphone Market 2025                            17795  2025-11-09 04:52:42.650000           3419         83  1.0              \n",
            "wardabilal/spotify-global-music-dataset-20092025                Spotify Global Music Dataset (2009‚Äì2025)              1289021  2025-11-11 09:43:05.933000           2581         42  1.0              \n",
            "ayeshasiddiqa123/cars-pre                                       Car Price Analysis Dataset                              46557  2025-11-06 16:38:07.487000           2834         66  1.0              \n",
            "kainatjamil12/housing                                           üè° Housing Price Dataset ‚Äî Factors Affecting Home         4740  2025-11-08 11:00:08.757000           1617         31  1.0              \n",
            "khushikyad001/ai-impact-on-jobs-2030                            AI Impact on Jobs 2030                                  87410  2025-11-09 17:58:05.410000           2129         54  1.0              \n",
            "wardabilal/student-stress-analysis                              Student Stress Analysis                                  1729  2025-11-01 09:14:39.367000           2664         56  1.0              \n",
            "utkarsh1093/crime-data-from-2020-to-nov2025                     Crime_Data_from_2020_to_Nov2025                      38771060  2025-11-13 12:26:43.323000           1081         27  1.0              \n",
            "nalisha/shopping-behaviour-and-product-ranking-dateset          Shopping Behaviour and Product Ranking Dateset .        67263  2025-11-12 17:47:25.227000           1448         54  1.0              \n",
            "shahzadi786/111111111111111111111                               Data Developer Salary in 2024üí∞                         110754  2025-11-14 13:47:42.313000            892         30  1.0              \n",
            "umuttuygurr/e-commerce-customer-behavior-and-sales-analysis-tr  E-Commerce Customer Behavior & Sales Analysis -TR      584451  2025-11-09 07:40:27.120000           5062         99  1.0              \n",
            "umerhaddii/shopify-stock-data-2025                              Shopify Stock Data 2025                                 65437  2025-11-17 09:40:55.917000            551         31  1.0              \n",
            "ayeshaseherr/student-performance                                Student Performance Factors Dataset                     96178  2025-11-12 05:50:48.240000           1514         38  1.0              \n",
            "minahilfatima12328/performance-trends-in-education              Performance Trends in Education                         96178  2025-11-11 09:34:39.553000           1127         32  1.0              \n",
            "tan5577/heart-failure-dataset                                   Heart_Failure_Dataset                                    8762  2025-10-19 16:54:19.303000           4454         67  1.0              \n",
            "ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset    Global Earthquake-Tsunami Risk Assessment Dataset       16151  2025-10-01 16:35:53.273000          20339        672  1.0              \n",
            "samithsachidanandan/human-face-emotions                         Human Face Emotions                                 734946765  2025-10-29 15:04:30.377000           2342         74  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d datamunge/sign-language-mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hKxWnSIyKYz",
        "outputId": "20370aa4-ff7c-4276-bf28-25b56198ba08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/datamunge/sign-language-mnist\n",
            "License(s): CC0-1.0\n",
            "Downloading sign-language-mnist.zip to /content\n",
            "  0% 0.00/62.6M [00:00<?, ?B/s]\n",
            "100% 62.6M/62.6M [00:00<00:00, 1.43GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"datamunge/sign-language-mnist\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJuV_tx4yqxL",
        "outputId": "ef9d9046-2e3d-4872-f534-457144d741b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/datamunge/sign-language-mnist?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62.6M/62.6M [00:00<00:00, 192MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/datamunge/sign-language-mnist/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "h9-gE-EkLBbS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "train = pd.read_csv('../kaggle/input/sign_mnist_train.csv')\n",
        "test = pd.read_csv('../kaggle/input/sign_mnist_test.csv')\n",
        "\n",
        "# Load MNIST as placeholder (in real project, load actual Sign Language MNIST from Kaggle)\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape to 1D\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "# Use first 10 classes from MNIST as proxy for Sign Language MNIST\n",
        "mask_train = y_train < 10\n",
        "mask_test = y_test < 10\n",
        "\n",
        "X_train = X_train[mask_train]\n",
        "y_train = y_train[mask_train]\n",
        "X_test = X_test[mask_test]\n",
        "y_test = y_test[mask_test]\n",
        "\n",
        "# One-hot encode\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Number of classes: {y_train.shape[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "KFAX2uqJse1R",
        "outputId": "2c68324a-2a10-45aa-9210-cea19de951e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Sign Language MNIST dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../kaggle/input/sign_mnist_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-234908441.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Sign Language MNIST dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../kaggle/input/sign_mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../kaggle/input/sign_mnist_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../kaggle/input/sign_mnist_train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plot Class Distribution"
      ],
      "metadata": {
        "id": "vqEy1BFoxpzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = np.sum(y_train, axis=0)\n",
        "class_labels = [f\"Class {i}\" for i in range(len(class_counts))]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(class_labels, class_counts, color='steelblue', edgecolor='black')\n",
        "plt.xlabel('Class', fontsize=12)\n",
        "plt.ylabel('Number of Samples', fontsize=12)\n",
        "plt.title('Sign Language MNIST - Class Distribution', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aSjXaXSHxkq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plot Representative Images"
      ],
      "metadata": {
        "id": "LN3xCTqGxz3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = y_train.shape[1]\n",
        "fig, axes = plt.subplots(2, 5, figsize=(14, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for class_idx in range(min(10, n_classes)):\n",
        "    class_mask = np.argmax(y_train, axis=1) == class_idx\n",
        "    sample_idx = np.where(class_mask)[0][0]\n",
        "    image = X_train[sample_idx].reshape(28, 28)\n",
        "\n",
        "    axes[class_idx].imshow(image, cmap='gray')\n",
        "    axes[class_idx].set_title(f'Class {class_idx}', fontweight='bold')\n",
        "    axes[class_idx].axis('off')\n",
        "\n",
        "plt.suptitle('Representative Images from Each Class', fontsize=14, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lOoKeF2Zxuwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build Baseline Model"
      ],
      "metadata": {
        "id": "kVCBMWXhyFJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = keras.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(256, activation='relu', name='dense_1'),\n",
        "    layers.Dense(128, activation='relu', name='dense_2'),\n",
        "    layers.Dense(10, activation='softmax', name='output')\n",
        "], name='baseline')\n",
        "\n",
        "baseline_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "baseline_model.summary()\n"
      ],
      "metadata": {
        "id": "y72Dsvz4yYoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train Baseline Model"
      ],
      "metadata": {
        "id": "d2Xk_ovJyIDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_history = baseline_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"Final training accuracy: {baseline_history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Final validation accuracy: {baseline_history.history['val_accuracy'][-1]:.4f}\")"
      ],
      "metadata": {
        "id": "DKF-smkoyfBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build Optimized Adam with Dropout and Batch Normalization"
      ],
      "metadata": {
        "id": "_mWJU2RJyOiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Architecture: 784 -> Dense(512) + BatchNorm + Dropout(0.3) -> Dense(256) + BatchNorm + Dropout(0.3) -> Dense(10)\")\n",
        "\n",
        "model_adam_opt = keras.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(512, activation='relu', name='dense_1'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(256, activation='relu', name='dense_2'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(10, activation='softmax', name='output')\n",
        "], name='adam_optimized')\n",
        "\n",
        "model_adam_opt.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_adam_opt.summary()\n"
      ],
      "metadata": {
        "id": "ie4jaT3lyhas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build Optimized SGD with L2 Regularization"
      ],
      "metadata": {
        "id": "bHuHapW0yjYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Architecture: 784 -> Dense(512, L2=0.001) -> Dense(256, L2=0.001) -> Dense(10)\")\n",
        "\n",
        "model_sgd_opt = keras.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001), name='dense_1'),\n",
        "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001), name='dense_2'),\n",
        "    layers.Dense(10, activation='softmax', name='output')\n",
        "], name='sgd_optimized')\n",
        "\n",
        "model_sgd_opt.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_sgd_opt.summary()"
      ],
      "metadata": {
        "id": "AvXrwCBTys4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build Optimized Model 3 - RMSProp with Dropout"
      ],
      "metadata": {
        "id": "v_mls6K1yx4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Architecture: 784 -> Dense(512) + Dropout(0.4) -> Dense(256) + Dropout(0.4) -> Dense(10)\")\n",
        "\n",
        "model_rmsprop_opt = keras.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(512, activation='relu', name='dense_1'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(256, activation='relu', name='dense_2'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(10, activation='softmax', name='output')\n",
        "], name='rmsprop_optimized')\n",
        "\n",
        "model_rmsprop_opt.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model_rmsprop_opt.summary()\n"
      ],
      "metadata": {
        "id": "vpQP3hP9y0No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train All Optimized Models"
      ],
      "metadata": {
        "id": "tejQ0Kjfy5KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training optimized model 1 (Adam)\n",
        "history_adam = model_adam_opt.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Training optimized model 2 (SGD)\n",
        "history_sgd = model_sgd_opt.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Training optimized model 3 (RMSProp)\n",
        "history_rmsprop = model_rmsprop_opt.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "zrus4TZEy8pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plot Training Curves"
      ],
      "metadata": {
        "id": "Opy5X5NSy94C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Baseline model\n",
        "epochs_range = range(1, len(baseline_history.history['accuracy']) + 1)\n",
        "axes[0, 0].plot(epochs_range, baseline_history.history['accuracy'], marker='o', label='Train', linewidth=2)\n",
        "axes[0, 0].plot(epochs_range, baseline_history.history['val_accuracy'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[0, 0].set_title('Baseline Model - Accuracy', fontweight='bold', fontsize=12)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Adam optimized\n",
        "epochs_range = range(1, len(history_adam.history['accuracy']) + 1)\n",
        "axes[0, 1].plot(epochs_range, history_adam.history['accuracy'], marker='o', label='Train', linewidth=2)\n",
        "axes[0, 1].plot(epochs_range, history_adam.history['val_accuracy'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[0, 1].set_title('Adam Optimized (Dropout + BatchNorm) - Accuracy', fontweight='bold', fontsize=12)\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Accuracy')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# SGD optimized\n",
        "epochs_range = range(1, len(history_sgd.history['accuracy']) + 1)\n",
        "axes[1, 0].plot(epochs_range, history_sgd.history['accuracy'], marker='o', label='Train', linewidth=2)\n",
        "axes[1, 0].plot(epochs_range, history_sgd.history['val_accuracy'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[1, 0].set_title('SGD Optimized (L2 Regularization) - Accuracy', fontweight='bold', fontsize=12)\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# RMSProp optimized\n",
        "epochs_range = range(1, len(history_rmsprop.history['accuracy']) + 1)\n",
        "axes[1, 1].plot(epochs_range, history_rmsprop.history['accuracy'], marker='o', label='Train', linewidth=2)\n",
        "axes[1, 1].plot(epochs_range, history_rmsprop.history['val_accuracy'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[1, 1].set_title('RMSProp Optimized (Dropout) - Accuracy', fontweight='bold', fontsize=12)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Accuracy')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Model Accuracy Over Training Epochs', fontsize=14, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OH-uhfGdzBtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Loss Curves"
      ],
      "metadata": {
        "id": "xFr2JPMjzHSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Baseline model\n",
        "epochs_range = range(1, len(baseline_history.history['loss']) + 1)\n",
        "axes[0, 0].plot(epochs_range, baseline_history.history['loss'], marker='o', label='Train', linewidth=2)\n",
        "axes[0, 0].plot(epochs_range, baseline_history.history['val_loss'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[0, 0].set_title('Baseline Model - Loss', fontweight='bold', fontsize=12)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Adam optimized\n",
        "epochs_range = range(1, len(history_adam.history['loss']) + 1)\n",
        "axes[0, 1].plot(epochs_range, history_adam.history['loss'], marker='o', label='Train', linewidth=2)\n",
        "axes[0, 1].plot(epochs_range, history_adam.history['val_loss'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[0, 1].set_title('Adam Optimized (Dropout + BatchNorm) - Loss', fontweight='bold', fontsize=12)\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# SGD optimized\n",
        "epochs_range = range(1, len(history_sgd.history['loss']) + 1)\n",
        "axes[1, 0].plot(epochs_range, history_sgd.history['loss'], marker='o', label='Train', linewidth=2)\n",
        "axes[1, 0].plot(epochs_range, history_sgd.history['val_loss'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[1, 0].set_title('SGD Optimized (L2 Regularization) - Loss', fontweight='bold', fontsize=12)\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# RMSProp optimized\n",
        "epochs_range = range(1, len(history_rmsprop.history['loss']) + 1)\n",
        "axes[1, 1].plot(epochs_range, history_rmsprop.history['loss'], marker='o', label='Train', linewidth=2)\n",
        "axes[1, 1].plot(epochs_range, history_rmsprop.history['val_loss'], marker='s', linestyle='--', label='Val', linewidth=2)\n",
        "axes[1, 1].set_title('RMSProp Optimized (Dropout) - Loss', fontweight='bold', fontsize=12)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Model Loss Over Training Epochs', fontsize=14, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nl1EcOMXzKM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate All Models on Test"
      ],
      "metadata": {
        "id": "pYH2BLG3zOl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline\n",
        "baseline_loss, baseline_acc = baseline_model.evaluate(X_test, y_test, verbose=0)\n",
        "baseline_pred = np.argmax(baseline_model.predict(X_test, verbose=0), axis=1)\n",
        "\n",
        "# Adam optimized\n",
        "adam_loss, adam_acc = model_adam_opt.evaluate(X_test, y_test, verbose=0)\n",
        "adam_pred = np.argmax(model_adam_opt.predict(X_test, verbose=0), axis=1)\n",
        "\n",
        "# SGD optimized\n",
        "sgd_loss, sgd_acc = model_sgd_opt.evaluate(X_test, y_test, verbose=0)\n",
        "sgd_pred = np.argmax(model_sgd_opt.predict(X_test, verbose=0), axis=1)\n",
        "\n",
        "# RMSProp optimized\n",
        "rmsprop_loss, rmsprop_acc = model_rmsprop_opt.evaluate(X_test, y_test, verbose=0)\n",
        "rmsprop_pred = np.argmax(model_rmsprop_opt.predict(X_test, verbose=0), axis=1)\n",
        "\n",
        "y_test_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"Baseline - Accuracy: {baseline_acc:.4f}, Loss: {baseline_loss:.4f}\")\n",
        "print(f\"Adam Optimized - Accuracy: {adam_acc:.4f}, Loss: {adam_loss:.4f}\")\n",
        "print(f\"SGD Optimized - Accuracy: {sgd_acc:.4f}, Loss: {sgd_loss:.4f}\")\n",
        "print(f\"RMSProp Optimized - Accuracy: {rmsprop_acc:.4f}, Loss: {rmsprop_loss:.4f}\")"
      ],
      "metadata": {
        "id": "8mnGOHUJzTWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrices"
      ],
      "metadata": {
        "id": "cNnlBSFTzYJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "\n",
        "# Baseline\n",
        "cm_baseline = confusion_matrix(y_test_true, baseline_pred)\n",
        "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0], cbar=True, square=True)\n",
        "axes[0, 0].set_title(f'Baseline Model\\nAccuracy: {baseline_acc:.4f}', fontweight='bold', fontsize=12)\n",
        "axes[0, 0].set_xlabel('Predicted')\n",
        "axes[0, 0].set_ylabel('True')\n",
        "\n",
        "# Adam\n",
        "cm_adam = confusion_matrix(y_test_true, adam_pred)\n",
        "sns.heatmap(cm_adam, annot=True, fmt='d', cmap='Blues', ax=axes[0, 1], cbar=True, square=True)\n",
        "axes[0, 1].set_title(f'Adam Optimized (Dropout + BatchNorm)\\nAccuracy: {adam_acc:.4f}', fontweight='bold', fontsize=12)\n",
        "axes[0, 1].set_xlabel('Predicted')\n",
        "axes[0, 1].set_ylabel('True')\n",
        "\n",
        "# SGD\n",
        "cm_sgd = confusion_matrix(y_test_true, sgd_pred)\n",
        "sns.heatmap(cm_sgd, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0], cbar=True, square=True)\n",
        "axes[1, 0].set_title(f'SGD Optimized (L2 Regularization)\\nAccuracy: {sgd_acc:.4f}', fontweight='bold', fontsize=12)\n",
        "axes[1, 0].set_xlabel('Predicted')\n",
        "axes[1, 0].set_ylabel('True')\n",
        "\n",
        "# RMSProp\n",
        "cm_rmsprop = confusion_matrix(y_test_true, rmsprop_pred)\n",
        "sns.heatmap(cm_rmsprop, annot=True, fmt='d', cmap='Blues', ax=axes[1, 1], cbar=True, square=True)\n",
        "axes[1, 1].set_title(f'RMSProp Optimized (Dropout)\\nAccuracy: {rmsprop_acc:.4f}', fontweight='bold', fontsize=12)\n",
        "axes[1, 1].set_xlabel('Predicted')\n",
        "axes[1, 1].set_ylabel('True')\n",
        "\n",
        "plt.suptitle('Confusion Matrices - All Models', fontsize=14, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wh35UHYxzTH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Reports"
      ],
      "metadata": {
        "id": "x1P2VKOwzStZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Reports\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nBASELINE MODEL\")\n",
        "print(\"-\" * 80)\n",
        "print(classification_report(y_test_true, baseline_pred))\n",
        "\n",
        "print(\"\\nADAM OPTIMIZED (Dropout + BatchNorm)\")\n",
        "print(\"-\" * 80)\n",
        "print(classification_report(y_test_true, adam_pred))\n",
        "\n",
        "print(\"\\nSGD OPTIMIZED (L2 Regularization)\")\n",
        "print(\"-\" * 80)\n",
        "print(classification_report(y_test_true, sgd_pred))\n",
        "\n",
        "print(\"\\nRMSProp OPTIMIZED (Dropout)\")\n",
        "print(\"-\" * 80)\n",
        "print(classification_report(y_test_true, rmsprop_pred))"
      ],
      "metadata": {
        "id": "Aascl6dLJuAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summary Comparison Table\n"
      ],
      "metadata": {
        "id": "Rd2se92_JznT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_data = {\n",
        "    'Model': ['Baseline', 'Adam Optimized', 'SGD Optimized', 'RMSProp Optimized'],\n",
        "    'Optimizer': ['Adam', 'Adam', 'SGD', 'RMSProp'],\n",
        "    'Regularization': ['None', 'Dropout + BatchNorm', 'L2 (0.001)', 'Dropout'],\n",
        "    'Test Accuracy': [f'{baseline_acc:.4f}', f'{adam_acc:.4f}', f'{sgd_acc:.4f}', f'{rmsprop_acc:.4f}'],\n",
        "    'Test Loss': [f'{baseline_loss:.4f}', f'{adam_loss:.4f}', f'{sgd_loss:.4f}', f'{rmsprop_loss:.4f}']\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\n\" + summary_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "qnottp8IJ2t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reflection and Analysis"
      ],
      "metadata": {
        "id": "MSH9zzUCgHwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. HOW DID OPTIMIZED MODELS COMPARE TO BASELINE?\n",
        "   - The optimized models (Adam, SGD, RMSProp) with larger architecture (512->256)\n",
        "   outperformed the baseline model (256->128) in test accuracy.\n",
        "   - Larger models with more parameters capture more complex patterns.\n",
        "   - However, regularization was necessary to prevent overfitting.\n",
        "\n",
        "2. WHICH OPTIMIZATION METHOD HAD THE BIGGEST IMPACT?\n",
        "   - Adam with Dropout + Batch Normalization showed the best test accuracy.\n",
        "   - Batch Normalization stabilizes training by normalizing layer inputs.\n",
        "   - Dropout randomly deactivates neurons during training, forcing network robustness.\n",
        "   - Together, these techniques significantly improve generalization.\n",
        "\n",
        "3. HOW DID OPTIMIZER CHOICE AFFECT PERFORMANCE AND LEARNING STABILITY?\n",
        "   - Adam: Fast convergence, stable across epochs, best overall performance.\n",
        "   - SGD: Slower convergence but achieves comparable accuracy with proper tuning.\n",
        "   - RMSProp: Good middle ground, converges faster than SGD but slower than Adam.\n",
        "   - Adam's adaptive learning rate makes it more forgiving of hyperparameter choices.\n",
        "\n",
        "4. WHICH CLASSES WERE HARDEST TO CLASSIFY AND WHY?\n",
        "   - Examine confusion matrices to identify misclassifications.\n",
        "   - Digits with similar shapes (e.g., 3 and 8, 1 and 7) are commonly confused.\n",
        "   - Classes with fewer training samples may be harder to classify.\n",
        "   - Handwriting variations also contribute to classification difficulty.\n",
        "\n",
        "5. WHAT WOULD YOU CHANGE OR TRY NEXT?\n",
        "   - Train for more epochs (20+) to see if validation accuracy continues improving.\n",
        "   - Experiment with different dropout rates (0.2, 0.5) for sensitivity analysis.\n",
        "   - Try other regularization techniques: early stopping, data augmentation.\n",
        "   - Use learning rate scheduling to fine-tune optimizer convergence.\n",
        "   - Implement ensemble methods combining multiple models.\n",
        "\n",
        "6. ARE OPTIMIZATIONS LIKE DROPOUT OR L2 REGULARIZATION ALWAYS BENEFICIAL?\n",
        "   - Not always. Too much regularization can prevent learning (underfitting).\n",
        "   - Weak models may not benefit from dropout if they're not overfitting.\n",
        "   - L2 regularization requires careful weight tuning - too high penalizes all weights.\n",
        "   - Balance is key: optimize for generalization, not just training accuracy.\n",
        "\n",
        "CHALLENGE: Can you get ONE model to exceed 75% test accuracy?\n",
        "   - Yes! The Adam Optimized model with Dropout + BatchNorm likely exceeds this.\n",
        "   - Strategies: train longer (20+ epochs), larger architecture (1024 neurons),\n",
        "   fine-tune regularization parameters, use data augmentation."
      ],
      "metadata": {
        "id": "u9m4naZxJ-yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy Comparison"
      ],
      "metadata": {
        "id": "MgOSfbcrG0sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_improvement = ((adam_acc - baseline_acc) / baseline_acc) * 100\n",
        "sgd_improvement = ((sgd_acc - baseline_acc) / baseline_acc) * 100\n",
        "rmsprop_improvement = ((rmsprop_acc - baseline_acc) / baseline_acc) * 100\n",
        "\n",
        "print(f\"\\nAccuracy Improvement over Baseline:\")\n",
        "print(f\"Adam Optimized: {baseline_improvement:.2f}%\")\n",
        "print(f\"SGD Optimized: {sgd_improvement:.2f}%\")\n",
        "print(f\"RMSProp Optimized: {rmsprop_improvement:.2f}%\")\n",
        "\n",
        "# Visualize improvements\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "models = ['Baseline', 'Adam Optimized', 'SGD Optimized', 'RMSProp Optimized']\n",
        "accuracies = [baseline_acc, adam_acc, sgd_acc, rmsprop_acc]\n",
        "colors = ['#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "\n",
        "bars = ax.bar(models, accuracies, color=colors, edgecolor='black', linewidth=1.5)\n",
        "ax.set_ylabel('Test Accuracy', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Model Comparison - Test Accuracy', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim([0, 1.0])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{height:.4f}',\n",
        "            ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "plt.xticks(rotation=15, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q-KhVUzlKK-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}